{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 636model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZYHC0XOvjYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG9jbsQVueU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import csv\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbBQ69_hPudh",
        "colab_type": "code",
        "outputId": "1f0a0887-87ab-4d77-a8dc-78ef86f19d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3ic_oC0Yq9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read json 2-d pose as data, without using: \n",
        "#     {15, \"REye\"},\n",
        "#     {16, \"LEye\"},\n",
        "#     {17, \"REar\"},\n",
        "#     {18, \"LEar\"}\n",
        "\n",
        "basepath1 = '/content/drive/My Drive/636project/data/fall_UR/fall-cam0'\n",
        "basepath2 = '/content/drive/My Drive/636project/data/adl_UR'\n",
        "\n",
        "def input_data(basepath):\n",
        "  data = []\n",
        "  entries = os.listdir(basepath)\n",
        "  for entry in entries:\n",
        "    path = os.path.join(basepath, entry)\n",
        "    frames = os.listdir(path)\n",
        "    for frame in frames:\n",
        "      frame_path = os.path.join(path, frame)\n",
        "      with open(frame_path, mode='r') as json_file:\n",
        "        people_dict = json.load(json_file)\n",
        "        people = people_dict[\"people\"]\n",
        "        pose_keypoints_2d = []\n",
        "        # fill missing data as 0\n",
        "        if len(people) == 0:\n",
        "          pose_keypoints_2d = [0] * 63\n",
        "        else:\n",
        "          full_pose = people[0].get(\"pose_keypoints_2d\")\n",
        "          pose_keypoints_2d = full_pose[:45] + full_pose[57:]\n",
        "         \n",
        "        pose_keypoints_2d.append(frame.split('.')[0])\n",
        "        # each pose_keypoints_2d: \n",
        "        # [431.949, 196.241, 0.0564434, 437.194, 187.749, 0.552267,...'fall-06-cam0_000000000065_keypoints']\n",
        "        data.append(pose_keypoints_2d)        \n",
        "  return data\n",
        "\n",
        "  \n",
        "data1 = input_data(basepath1)\n",
        "print(len(data1))\n",
        "\n",
        "data2 = input_data(basepath2)\n",
        "print(len(data2))\n",
        "\n",
        "video_data = data1 + data2\n",
        "print(len(video_data))\n",
        "\n",
        "df = pd.DataFrame.from_records(video_data)\n",
        "df.to_csv (r'/content/drive/My Drive/636project/raw_data.csv', index = False, header=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v61HcYuUSK6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video_data = []\n",
        "path_of_video = '/content/drive/My Drive/636project/raw_data.csv'\n",
        "\n",
        "# read the video data csv,\n",
        "# it is faster than run the above code each time\n",
        "def read_data(path):\n",
        "  with open(path, mode='r') as csv_file:\n",
        "    reader = csv.reader(csv_file)\n",
        "    for row in reader:\n",
        "      video_data.append(row)\n",
        "\n",
        "read_data(path_of_video)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DchOlwQNKUA",
        "colab_type": "code",
        "outputId": "d6ad4371-61a2-4600-a6d7-ab3214f3347f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# target: csv file\n",
        "target = []\n",
        "path1 = '/content/drive/My Drive/636project/target/urfall-cam0-falls.csv'\n",
        "path2 = '/content/drive/My Drive/636project/target/urfall-cam0-adls.csv'\n",
        "# in these csv of UR dataset, \n",
        "# '-1' means person is not lying, '1' means person is lying on the ground; '0' is temporary pose, when person \"is falling\"\n",
        "\n",
        "def input_fall(path):\n",
        "  falls = 0\n",
        "  not_fall = 0\n",
        "  with open(path, mode='r') as csv_file:\n",
        "    reader = csv.reader(csv_file)\n",
        "    for row in reader:\n",
        "      record = []\n",
        "      record.append(row[0])\n",
        "      record.append(row[1])\n",
        "      label = row[2]\n",
        "      if label == '1' or label == '0':\n",
        "        falls += 1\n",
        "        record.append(1)        \n",
        "      else:\n",
        "        not_fall += 1\n",
        "        record.append(0)\n",
        "      # each record: [<video_id>, <frame_id>, label], eg: ['fall-17', '22', 0] \n",
        "      target.append(record)\n",
        "  print(\"falls\", falls)\n",
        "  print(\"not_fall\", not_fall)\n",
        "\n",
        "# though laying in the video, but it is not fall, so I mark 0 as label\n",
        "def input_adl(path):\n",
        "  with open(path, mode='r') as csv_file:\n",
        "    reader = csv.reader(csv_file)\n",
        "    for row in reader:\n",
        "      record = []\n",
        "      record.append(row[0])\n",
        "      record.append(row[1])\n",
        "      record.append(0)\n",
        "      target.append(record)\n",
        "\n",
        "input_fall(path1)\n",
        "print(len(target))\n",
        "\n",
        "input_adl(path2)\n",
        "print(len(target))\n",
        "\n",
        "df = pd.DataFrame.from_records(target)\n",
        "df.to_csv (r'/content/drive/My Drive/636project/target_data.csv', index = False, header=False)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "falls 1803\n",
            "not_fall 1192\n",
            "2995\n",
            "11544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtMEv5GabKlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make dictionary of target \n",
        "target_csv_path = '/content/drive/My Drive/636project/target_data.csv'\n",
        "idx = 0\n",
        "idx_dict = {}\n",
        "\n",
        "with open(target_csv_path, mode='r') as csv_file:\n",
        "  reader = csv.reader(csv_file)\n",
        "  for row in reader:\n",
        "    # each row: [<video_id>, <frame_id>, label], eg: ['fall-17', '22', 0] \n",
        "    idx_dict['.'.join(row[:2])] = idx  # {'fall-17.22' : 112}\n",
        "    idx += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns3vNaNj5L3G",
        "colab_type": "code",
        "outputId": "f089cf12-9b3a-4291-8141-a2bfbdfa3219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "bodylandmark = []\n",
        "label = []\n",
        "\n",
        "for landmark in video_data:\n",
        "  video_name = landmark[-1].split('_')  # 'fall-01-cam0_000000000004'\n",
        "  a = video_name[0].split('-')\n",
        "  video_type = a[0] # 'fall'\n",
        "  video_id = a[1]   # '01'\n",
        "  frame_id = str(int(video_name[1])) # '000000000004' become '4'\n",
        "  try:\n",
        "    a = '.'.join([video_id, frame_id])\n",
        "    b = '-'.join([video_type, a])\n",
        "    label.append(target[idx_dict[b]][-1])\n",
        "    bodylandmark.append(landmark[:-1])\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "print(bodylandmark[0])\n",
        "print(len(label))\n",
        "print(len(bodylandmark))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['520.972', '128.178', '0.833728', '544.571', '130.782', '0.739747', '540.636', '132.754', '0.726633', '553.086', '154.999', '0.800764', '541.285', '166.155', '0.742877', '549.144', '129.467', '0.745059', '572.703', '155.035', '0.841464', '543.266', '171.369', '0.817947', '572.067', '169.415', '0.607432', '564.874', '166.16', '0.534525', '526.875', '181.191', '0.862423', '554.389', '217.851', '0.612664', '577.962', '170.732', '0.619415', '535.402', '188.398', '0.760066', '560.284', '220.479', '0.65847', '545.882', '232.266', '0.604373', '553.078', '232.915', '0.532739', '566.184', '222.453', '0.655722', '541.939', '229.002', '0.399536', '541.943', '227.687', '0.344383', '560.285', '217.223', '0.153482']\n",
            "11475\n",
            "11475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjQH8nEGum9U",
        "colab_type": "code",
        "outputId": "714fa04d-4eb3-461a-ed8a-c01821b3f630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# normalize data \n",
        "for record in bodylandmark:\n",
        "  for i in range(0, 63, 3):\n",
        "    record[i] = float(record[i])/ 640\n",
        "    record[i + 1] = float(record[i + 1]) / 480\n",
        "\n",
        "print(bodylandmark[0])\n",
        "print(len(label))\n",
        "print(len(bodylandmark))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.81401875, 0.2670375, '0.833728', 0.8508921875000001, 0.2724625, '0.739747', 0.8447437499999999, 0.2765708333333333, '0.726633', 0.864196875, 0.32291458333333334, '0.800764', 0.8457578124999999, 0.34615625, '0.742877', 0.8580375, 0.2697229166666667, '0.745059', 0.8948484375, 0.32298958333333333, '0.841464', 0.848853125, 0.35701875, '0.817947', 0.8938546875, 0.35294791666666664, '0.607432', 0.882615625, 0.3461666666666667, '0.534525', 0.8232421875, 0.37748125, '0.862423', 0.8662328125000001, 0.45385625, '0.612664', 0.903065625, 0.3556916666666667, '0.619415', 0.8365656250000001, 0.3924958333333333, '0.760066', 0.87544375, 0.45933125, '0.65847', 0.8529406249999999, 0.48388749999999997, '0.604373', 0.864184375, 0.48523958333333334, '0.532739', 0.8846624999999999, 0.46344375, '0.655722', 0.8467796875, 0.4770875, '0.399536', 0.8467859375, 0.4743479166666667, '0.344383', 0.8754453124999999, 0.4525479166666667, '0.153482']\n",
            "11475\n",
            "11475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TseRjvqzZ9a",
        "colab_type": "code",
        "outputId": "06c8082e-38a2-4b9d-c310-0b3bf457a867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# make bodylandmark and label to be a same data frame\n",
        "all_data = []\n",
        "\n",
        "for i in range(len(bodylandmark)):\n",
        "  all_data.append([label[i]])\n",
        "  all_data[i] = all_data[i] + bodylandmark[i]\n",
        "\n",
        "print(all_data[0])\n",
        "print(len(all_data))\n",
        "print(len(all_data[0]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0.81401875, 0.2670375, '0.833728', 0.8508921875000001, 0.2724625, '0.739747', 0.8447437499999999, 0.2765708333333333, '0.726633', 0.864196875, 0.32291458333333334, '0.800764', 0.8457578124999999, 0.34615625, '0.742877', 0.8580375, 0.2697229166666667, '0.745059', 0.8948484375, 0.32298958333333333, '0.841464', 0.848853125, 0.35701875, '0.817947', 0.8938546875, 0.35294791666666664, '0.607432', 0.882615625, 0.3461666666666667, '0.534525', 0.8232421875, 0.37748125, '0.862423', 0.8662328125000001, 0.45385625, '0.612664', 0.903065625, 0.3556916666666667, '0.619415', 0.8365656250000001, 0.3924958333333333, '0.760066', 0.87544375, 0.45933125, '0.65847', 0.8529406249999999, 0.48388749999999997, '0.604373', 0.864184375, 0.48523958333333334, '0.532739', 0.8846624999999999, 0.46344375, '0.655722', 0.8467796875, 0.4770875, '0.399536', 0.8467859375, 0.4743479166666667, '0.344383', 0.8754453124999999, 0.4525479166666667, '0.153482']\n",
            "11475\n",
            "64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puE0mHIKnR3O",
        "colab_type": "code",
        "outputId": "6448f36a-d0ff-41f7-ee51-9950d62b3c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# up-sampling to make the data balance\n",
        "# Separate majority and minority classes\n",
        "df = pd.DataFrame.from_records(all_data)\n",
        "header = ['label']\n",
        "for i in range(63):\n",
        "  header.append(i)\n",
        "\n",
        "df.columns = header\n",
        "df_majority = df[df.label==0]\n",
        "df_minority = df[df.label==1]\n",
        "print(\"before re-sampling, fall vs not fall: \")\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "from sklearn.utils import resample\n",
        "print(\"begin to re sample...\")\n",
        "# Upsample minority class\n",
        "df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,      # sample with replacement\n",
        "                                 n_samples=9741)    # to match majority class\n",
        "                                  \n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
        " \n",
        "print(\"after re-sampling...\")\n",
        "# Display new class counts\n",
        "df_upsampled.label.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before re-sampling, fall vs not fall: \n",
            "0    9702\n",
            "1    1773\n",
            "Name: label, dtype: int64\n",
            "begin to re sample...\n",
            "after re-sampling...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    9741\n",
              "0    9702\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok4SPC0u4LZX",
        "colab_type": "code",
        "outputId": "07e3b1a9-166f-47c3-ed6d-8681c1bc6def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "all_data = df_upsampled.values\n",
        "\n",
        "print(all_data[0])\n",
        "print(len(all_data))\n",
        "print(len(all_data[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0.81401875 0.2670375 '0.833728' 0.8508921875000001 0.2724625 '0.739747'\n",
            " 0.8447437499999999 0.2765708333333333 '0.726633' 0.864196875\n",
            " 0.32291458333333334 '0.800764' 0.8457578124999999 0.34615625 '0.742877'\n",
            " 0.8580375 0.2697229166666667 '0.745059' 0.8948484375 0.32298958333333333\n",
            " '0.841464' 0.848853125 0.35701875 '0.817947' 0.8938546875\n",
            " 0.35294791666666664 '0.607432' 0.882615625 0.3461666666666667 '0.534525'\n",
            " 0.8232421875 0.37748125 '0.862423' 0.8662328125000001 0.45385625\n",
            " '0.612664' 0.903065625 0.3556916666666667 '0.619415' 0.8365656250000001\n",
            " 0.3924958333333333 '0.760066' 0.87544375 0.45933125 '0.65847'\n",
            " 0.8529406249999999 0.48388749999999997 '0.604373' 0.864184375\n",
            " 0.48523958333333334 '0.532739' 0.8846624999999999 0.46344375 '0.655722'\n",
            " 0.8467796875 0.4770875 '0.399536' 0.8467859375 0.4743479166666667\n",
            " '0.344383' 0.8754453124999999 0.4525479166666667 '0.153482']\n",
            "19443\n",
            "64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEn4pkbz0SPf",
        "colab_type": "code",
        "outputId": "514de110-6c47-4e91-dee2-83e1ab717170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# split data into train and test set\n",
        "np.random.shuffle(all_data)\n",
        "split_point = len(all_data) // 9\n",
        "print(split_point)\n",
        "test_data = all_data[:split_point]\n",
        "train_data = all_data[split_point: ]\n",
        "\n",
        "print(len(test_data))\n",
        "print(len(train_data))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2160\n",
            "2160\n",
            "17283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxdTfMk3TuYA",
        "colab_type": "code",
        "outputId": "4fb5107b-c3e6-4702-cd46-895091b2ae86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#train model using lstm\n",
        "\n",
        "from keras.layers import LSTM\n",
        "from keras import callbacks\n",
        "from keras import layers\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "\n",
        "def scheduler(epoch):\n",
        "  if epoch < 10:\n",
        "    return 0.001\n",
        "  else:\n",
        "    return 0.001 * np.exp(0.1 * (10 - epoch))\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for record in train_data:\n",
        "  x_train.append(record[1:])\n",
        "  label = int(record[0])\n",
        "  y_train.append(label) \n",
        "\n",
        "x_train = array(x_train)\n",
        "x_train = x_train.reshape((len(x_train), 1, len(x_train[0])))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(1, 63)))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=5),\n",
        "                    callbacks.LearningRateScheduler(scheduler)])\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13826 samples, validate on 3457 samples\n",
            "Epoch 1/100\n",
            "13826/13826 [==============================] - 3s 251us/step - loss: 0.5328 - acc: 0.7561 - val_loss: 0.5344 - val_acc: 0.7290\n",
            "Epoch 2/100\n",
            "13826/13826 [==============================] - 3s 192us/step - loss: 0.4344 - acc: 0.8009 - val_loss: 0.4192 - val_acc: 0.8102\n",
            "Epoch 3/100\n",
            "13826/13826 [==============================] - 3s 194us/step - loss: 0.4065 - acc: 0.8126 - val_loss: 0.3890 - val_acc: 0.8178\n",
            "Epoch 4/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.3900 - acc: 0.8162 - val_loss: 0.4082 - val_acc: 0.8021\n",
            "Epoch 5/100\n",
            "13826/13826 [==============================] - 3s 195us/step - loss: 0.3775 - acc: 0.8220 - val_loss: 0.6012 - val_acc: 0.7009\n",
            "Epoch 6/100\n",
            "13826/13826 [==============================] - 3s 191us/step - loss: 0.3670 - acc: 0.8279 - val_loss: 0.3756 - val_acc: 0.8235\n",
            "Epoch 7/100\n",
            "13826/13826 [==============================] - 3s 193us/step - loss: 0.3567 - acc: 0.8321 - val_loss: 0.4106 - val_acc: 0.7940\n",
            "Epoch 8/100\n",
            "13826/13826 [==============================] - 3s 194us/step - loss: 0.3491 - acc: 0.8370 - val_loss: 0.3507 - val_acc: 0.8314\n",
            "Epoch 9/100\n",
            "13826/13826 [==============================] - 3s 187us/step - loss: 0.3405 - acc: 0.8434 - val_loss: 0.3353 - val_acc: 0.8429\n",
            "Epoch 10/100\n",
            "13826/13826 [==============================] - 3s 196us/step - loss: 0.3344 - acc: 0.8441 - val_loss: 0.3464 - val_acc: 0.8363\n",
            "Epoch 11/100\n",
            "13826/13826 [==============================] - 3s 191us/step - loss: 0.3277 - acc: 0.8503 - val_loss: 0.3359 - val_acc: 0.8415\n",
            "Epoch 12/100\n",
            "13826/13826 [==============================] - 3s 191us/step - loss: 0.3218 - acc: 0.8538 - val_loss: 0.3193 - val_acc: 0.8513\n",
            "Epoch 13/100\n",
            "13826/13826 [==============================] - 3s 191us/step - loss: 0.3147 - acc: 0.8544 - val_loss: 0.3172 - val_acc: 0.8504\n",
            "Epoch 14/100\n",
            "13826/13826 [==============================] - 3s 190us/step - loss: 0.3093 - acc: 0.8577 - val_loss: 0.3126 - val_acc: 0.8551\n",
            "Epoch 15/100\n",
            "13826/13826 [==============================] - 3s 194us/step - loss: 0.3049 - acc: 0.8637 - val_loss: 0.3132 - val_acc: 0.8571\n",
            "Epoch 16/100\n",
            "13826/13826 [==============================] - 3s 198us/step - loss: 0.3019 - acc: 0.8656 - val_loss: 0.3051 - val_acc: 0.8617\n",
            "Epoch 17/100\n",
            "13826/13826 [==============================] - 3s 191us/step - loss: 0.2977 - acc: 0.8665 - val_loss: 0.3112 - val_acc: 0.8562\n",
            "Epoch 18/100\n",
            "13826/13826 [==============================] - 3s 199us/step - loss: 0.2945 - acc: 0.8692 - val_loss: 0.2990 - val_acc: 0.8626\n",
            "Epoch 19/100\n",
            "13826/13826 [==============================] - 3s 198us/step - loss: 0.2917 - acc: 0.8708 - val_loss: 0.3108 - val_acc: 0.8562\n",
            "Epoch 20/100\n",
            "13826/13826 [==============================] - 3s 198us/step - loss: 0.2895 - acc: 0.8692 - val_loss: 0.2987 - val_acc: 0.8664\n",
            "Epoch 21/100\n",
            "13826/13826 [==============================] - 3s 203us/step - loss: 0.2872 - acc: 0.8734 - val_loss: 0.3330 - val_acc: 0.8423\n",
            "Epoch 22/100\n",
            "13826/13826 [==============================] - 3s 205us/step - loss: 0.2859 - acc: 0.8724 - val_loss: 0.2934 - val_acc: 0.8698\n",
            "Epoch 23/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2832 - acc: 0.8758 - val_loss: 0.3050 - val_acc: 0.8635\n",
            "Epoch 24/100\n",
            "13826/13826 [==============================] - 3s 199us/step - loss: 0.2822 - acc: 0.8751 - val_loss: 0.2906 - val_acc: 0.8695\n",
            "Epoch 25/100\n",
            "13826/13826 [==============================] - 3s 202us/step - loss: 0.2809 - acc: 0.8767 - val_loss: 0.2976 - val_acc: 0.8609\n",
            "Epoch 26/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2795 - acc: 0.8776 - val_loss: 0.2980 - val_acc: 0.8678\n",
            "Epoch 27/100\n",
            "13826/13826 [==============================] - 3s 203us/step - loss: 0.2781 - acc: 0.8781 - val_loss: 0.2881 - val_acc: 0.8739\n",
            "Epoch 28/100\n",
            "13826/13826 [==============================] - 3s 205us/step - loss: 0.2774 - acc: 0.8794 - val_loss: 0.2865 - val_acc: 0.8742\n",
            "Epoch 29/100\n",
            "13826/13826 [==============================] - 3s 208us/step - loss: 0.2764 - acc: 0.8797 - val_loss: 0.2859 - val_acc: 0.8733\n",
            "Epoch 30/100\n",
            "13826/13826 [==============================] - 3s 204us/step - loss: 0.2752 - acc: 0.8797 - val_loss: 0.2863 - val_acc: 0.8759\n",
            "Epoch 31/100\n",
            "13826/13826 [==============================] - 3s 202us/step - loss: 0.2743 - acc: 0.8812 - val_loss: 0.2848 - val_acc: 0.8747\n",
            "Epoch 32/100\n",
            "13826/13826 [==============================] - 3s 203us/step - loss: 0.2739 - acc: 0.8823 - val_loss: 0.2898 - val_acc: 0.8655\n",
            "Epoch 33/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2734 - acc: 0.8803 - val_loss: 0.2841 - val_acc: 0.8768\n",
            "Epoch 34/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2725 - acc: 0.8835 - val_loss: 0.2846 - val_acc: 0.8736\n",
            "Epoch 35/100\n",
            "13826/13826 [==============================] - 3s 196us/step - loss: 0.2721 - acc: 0.8828 - val_loss: 0.2832 - val_acc: 0.8753\n",
            "Epoch 36/100\n",
            "13826/13826 [==============================] - 3s 212us/step - loss: 0.2719 - acc: 0.8828 - val_loss: 0.2834 - val_acc: 0.8756\n",
            "Epoch 37/100\n",
            "13826/13826 [==============================] - 3s 207us/step - loss: 0.2711 - acc: 0.8821 - val_loss: 0.2827 - val_acc: 0.8768\n",
            "Epoch 38/100\n",
            "13826/13826 [==============================] - 3s 202us/step - loss: 0.2711 - acc: 0.8829 - val_loss: 0.2827 - val_acc: 0.8765\n",
            "Epoch 39/100\n",
            "13826/13826 [==============================] - 3s 199us/step - loss: 0.2708 - acc: 0.8834 - val_loss: 0.2874 - val_acc: 0.8742\n",
            "Epoch 40/100\n",
            "13826/13826 [==============================] - 3s 194us/step - loss: 0.2705 - acc: 0.8840 - val_loss: 0.2822 - val_acc: 0.8774\n",
            "Epoch 41/100\n",
            "13826/13826 [==============================] - 3s 200us/step - loss: 0.2702 - acc: 0.8838 - val_loss: 0.2823 - val_acc: 0.8759\n",
            "Epoch 42/100\n",
            "13826/13826 [==============================] - 3s 201us/step - loss: 0.2700 - acc: 0.8839 - val_loss: 0.2821 - val_acc: 0.8771\n",
            "Epoch 43/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2697 - acc: 0.8836 - val_loss: 0.2823 - val_acc: 0.8779\n",
            "Epoch 44/100\n",
            "13826/13826 [==============================] - 3s 201us/step - loss: 0.2696 - acc: 0.8841 - val_loss: 0.2815 - val_acc: 0.8774\n",
            "Epoch 45/100\n",
            "13826/13826 [==============================] - 3s 198us/step - loss: 0.2694 - acc: 0.8841 - val_loss: 0.2813 - val_acc: 0.8774\n",
            "Epoch 46/100\n",
            "13826/13826 [==============================] - 3s 195us/step - loss: 0.2692 - acc: 0.8845 - val_loss: 0.2826 - val_acc: 0.8776\n",
            "Epoch 47/100\n",
            "13826/13826 [==============================] - 3s 198us/step - loss: 0.2690 - acc: 0.8841 - val_loss: 0.2814 - val_acc: 0.8782\n",
            "Epoch 48/100\n",
            "13826/13826 [==============================] - 3s 203us/step - loss: 0.2689 - acc: 0.8841 - val_loss: 0.2813 - val_acc: 0.8785\n",
            "Epoch 49/100\n",
            "13826/13826 [==============================] - 3s 204us/step - loss: 0.2687 - acc: 0.8840 - val_loss: 0.2809 - val_acc: 0.8776\n",
            "Epoch 50/100\n",
            "13826/13826 [==============================] - 3s 204us/step - loss: 0.2687 - acc: 0.8843 - val_loss: 0.2811 - val_acc: 0.8782\n",
            "Epoch 51/100\n",
            "13826/13826 [==============================] - 3s 205us/step - loss: 0.2686 - acc: 0.8846 - val_loss: 0.2809 - val_acc: 0.8779\n",
            "Epoch 52/100\n",
            "13826/13826 [==============================] - 3s 200us/step - loss: 0.2685 - acc: 0.8842 - val_loss: 0.2811 - val_acc: 0.8782\n",
            "Epoch 53/100\n",
            "13826/13826 [==============================] - 3s 204us/step - loss: 0.2684 - acc: 0.8852 - val_loss: 0.2810 - val_acc: 0.8782\n",
            "Epoch 54/100\n",
            "13826/13826 [==============================] - 3s 198us/step - loss: 0.2683 - acc: 0.8851 - val_loss: 0.2807 - val_acc: 0.8797\n",
            "Epoch 55/100\n",
            "13826/13826 [==============================] - 3s 196us/step - loss: 0.2683 - acc: 0.8850 - val_loss: 0.2807 - val_acc: 0.8788\n",
            "Epoch 56/100\n",
            "13826/13826 [==============================] - 3s 198us/step - loss: 0.2682 - acc: 0.8853 - val_loss: 0.2809 - val_acc: 0.8782\n",
            "Epoch 57/100\n",
            "13826/13826 [==============================] - 3s 202us/step - loss: 0.2681 - acc: 0.8849 - val_loss: 0.2807 - val_acc: 0.8782\n",
            "Epoch 58/100\n",
            "13826/13826 [==============================] - 3s 201us/step - loss: 0.2681 - acc: 0.8851 - val_loss: 0.2806 - val_acc: 0.8768\n",
            "Epoch 59/100\n",
            "13826/13826 [==============================] - 3s 200us/step - loss: 0.2681 - acc: 0.8852 - val_loss: 0.2806 - val_acc: 0.8779\n",
            "Epoch 60/100\n",
            "13826/13826 [==============================] - 3s 204us/step - loss: 0.2680 - acc: 0.8850 - val_loss: 0.2807 - val_acc: 0.8782\n",
            "Epoch 61/100\n",
            "13826/13826 [==============================] - 3s 205us/step - loss: 0.2680 - acc: 0.8851 - val_loss: 0.2805 - val_acc: 0.8776\n",
            "Epoch 62/100\n",
            "13826/13826 [==============================] - 3s 198us/step - loss: 0.2679 - acc: 0.8853 - val_loss: 0.2805 - val_acc: 0.8788\n",
            "Epoch 63/100\n",
            "13826/13826 [==============================] - 3s 196us/step - loss: 0.2679 - acc: 0.8854 - val_loss: 0.2804 - val_acc: 0.8788\n",
            "Epoch 64/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2679 - acc: 0.8854 - val_loss: 0.2805 - val_acc: 0.8779\n",
            "Epoch 65/100\n",
            "13826/13826 [==============================] - 3s 196us/step - loss: 0.2679 - acc: 0.8853 - val_loss: 0.2805 - val_acc: 0.8779\n",
            "Epoch 66/100\n",
            "13826/13826 [==============================] - 3s 200us/step - loss: 0.2678 - acc: 0.8853 - val_loss: 0.2805 - val_acc: 0.8782\n",
            "Epoch 67/100\n",
            "13826/13826 [==============================] - 3s 201us/step - loss: 0.2678 - acc: 0.8852 - val_loss: 0.2805 - val_acc: 0.8779\n",
            "Epoch 68/100\n",
            "13826/13826 [==============================] - 3s 203us/step - loss: 0.2678 - acc: 0.8852 - val_loss: 0.2804 - val_acc: 0.8774\n",
            "Epoch 69/100\n",
            "13826/13826 [==============================] - 3s 201us/step - loss: 0.2678 - acc: 0.8851 - val_loss: 0.2804 - val_acc: 0.8782\n",
            "Epoch 70/100\n",
            "13826/13826 [==============================] - 3s 211us/step - loss: 0.2678 - acc: 0.8851 - val_loss: 0.2804 - val_acc: 0.8779\n",
            "Epoch 71/100\n",
            "13826/13826 [==============================] - 3s 200us/step - loss: 0.2677 - acc: 0.8851 - val_loss: 0.2805 - val_acc: 0.8779\n",
            "Epoch 72/100\n",
            "13826/13826 [==============================] - 3s 200us/step - loss: 0.2677 - acc: 0.8852 - val_loss: 0.2804 - val_acc: 0.8779\n",
            "Epoch 73/100\n",
            "13826/13826 [==============================] - 3s 202us/step - loss: 0.2677 - acc: 0.8855 - val_loss: 0.2804 - val_acc: 0.8779\n",
            "Epoch 74/100\n",
            "13826/13826 [==============================] - 3s 196us/step - loss: 0.2677 - acc: 0.8853 - val_loss: 0.2804 - val_acc: 0.8779\n",
            "Epoch 75/100\n",
            "13826/13826 [==============================] - 3s 195us/step - loss: 0.2677 - acc: 0.8853 - val_loss: 0.2804 - val_acc: 0.8779\n",
            "Epoch 76/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2677 - acc: 0.8853 - val_loss: 0.2804 - val_acc: 0.8779\n",
            "Epoch 77/100\n",
            "13826/13826 [==============================] - 3s 194us/step - loss: 0.2677 - acc: 0.8853 - val_loss: 0.2804 - val_acc: 0.8779\n",
            "Epoch 78/100\n",
            "13826/13826 [==============================] - 3s 195us/step - loss: 0.2677 - acc: 0.8851 - val_loss: 0.2804 - val_acc: 0.8779\n",
            "Epoch 79/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2677 - acc: 0.8852 - val_loss: 0.2804 - val_acc: 0.8779\n",
            "Epoch 80/100\n",
            "13826/13826 [==============================] - 3s 194us/step - loss: 0.2677 - acc: 0.8852 - val_loss: 0.2803 - val_acc: 0.8779\n",
            "Epoch 81/100\n",
            "13826/13826 [==============================] - 3s 194us/step - loss: 0.2677 - acc: 0.8851 - val_loss: 0.2803 - val_acc: 0.8779\n",
            "Epoch 82/100\n",
            "13826/13826 [==============================] - 3s 191us/step - loss: 0.2677 - acc: 0.8852 - val_loss: 0.2803 - val_acc: 0.8774\n",
            "Epoch 83/100\n",
            "13826/13826 [==============================] - 3s 199us/step - loss: 0.2676 - acc: 0.8853 - val_loss: 0.2803 - val_acc: 0.8774\n",
            "Epoch 84/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2676 - acc: 0.8851 - val_loss: 0.2803 - val_acc: 0.8779\n",
            "Epoch 85/100\n",
            "13826/13826 [==============================] - 3s 200us/step - loss: 0.2676 - acc: 0.8853 - val_loss: 0.2803 - val_acc: 0.8779\n",
            "Epoch 86/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2676 - acc: 0.8854 - val_loss: 0.2803 - val_acc: 0.8779\n",
            "Epoch 87/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2676 - acc: 0.8852 - val_loss: 0.2803 - val_acc: 0.8779\n",
            "Epoch 88/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2676 - acc: 0.8853 - val_loss: 0.2803 - val_acc: 0.8779\n",
            "Epoch 89/100\n",
            "13826/13826 [==============================] - 3s 191us/step - loss: 0.2676 - acc: 0.8853 - val_loss: 0.2803 - val_acc: 0.8779\n",
            "Epoch 90/100\n",
            "13826/13826 [==============================] - 3s 198us/step - loss: 0.2676 - acc: 0.8852 - val_loss: 0.2803 - val_acc: 0.8779\n",
            "Epoch 91/100\n",
            "13826/13826 [==============================] - 3s 198us/step - loss: 0.2676 - acc: 0.8853 - val_loss: 0.2803 - val_acc: 0.8779\n",
            "Epoch 92/100\n",
            "13826/13826 [==============================] - 3s 205us/step - loss: 0.2676 - acc: 0.8854 - val_loss: 0.2803 - val_acc: 0.8779\n",
            "Epoch 93/100\n",
            "13826/13826 [==============================] - 3s 197us/step - loss: 0.2676 - acc: 0.8853 - val_loss: 0.2803 - val_acc: 0.8779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFKFHBmxvZuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "10ae9f87-b7a5-45c2-f839-073b52a9c8aa"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 32)                12288     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 12,321\n",
            "Trainable params: 12,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB-7RM66Yp7w",
        "colab_type": "code",
        "outputId": "59400894-46dc-462d-cca4-cf2d57e23116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# plotting the results\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLyIScwr0IiIx9/8BF8dXcmP1g7sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdyJtNbDxV0x",
        "colab_type": "code",
        "outputId": "a6511d00-a056-466c-8f04-7ad1fce57284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# train the final model on all non-test data avaliable\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for record in test_data:\n",
        "  x_test.append(record[1:])\n",
        "  label = int(record[0])\n",
        "  y_test.append(label) \n",
        "\n",
        "x_test = array(x_test)\n",
        "x_test = x_test.reshape((len(x_test), 1, len(x_test[0])))\n",
        "\n",
        "test_score = model.evaluate(x_test, y_test)\n",
        "print(\"test loss:\")\n",
        "print(test_score[0])\n",
        "print(\"test accuracy:\")\n",
        "print(test_score[1])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2160/2160 [==============================] - 0s 84us/step\n",
            "test loss:\n",
            "0.283822970478623\n",
            "test accuracy:\n",
            "0.8685185185185185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR5MyMOF7zsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/drive/My Drive/636project/model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt6eBYBH70i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}